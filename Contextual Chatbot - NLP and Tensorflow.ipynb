{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHATBOTS - Using Natural Language Processing and Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this Jupyter Notebook, We are going to Build a Chatbot that Understands the Context of Sentense and Respond accordingly.\n",
    "These are the Things that we are going to do in this Project -\n",
    "1. Transforming the Conversational Intents into Tensorflow model (Neural Network using TFLEARN) using NLP and Save it as Pickle also.\n",
    "2. Load the Same Pickle and Model to Build the Framework to Process the Responses.\n",
    "3. At Last, We Show How the Inputs are Processed and Give the Reponses.\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "\n",
    "##### TFLEARN  - TFlearn is a modular and transparent deep learning library built on top of Tensorflow. It was designed to provide a higher-level API to TensorFlow in order to facilitate and speed-up experimentations, while remaining fully transparent and compatible with it.  (http://tflearn.org/)\n",
    "-------------------------------------------------------------------------------------------------------\n",
    "##### TENSORFLOW - TensorFlow is an end-to-end open source platform for machine learning. It has a comprehensive, flexible ecosystem of tools, libraries and community resources that lets researchers push the state-of-the-art in ML and developers easily build and deploy ML powered applications.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tflearn in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tflearn) (1.19.5)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tflearn) (7.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tflearn) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\hp\\anaconda3\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (2.24.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.4.5)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (49.2.0.post20200714)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->tensorflow) (1.34.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.25.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries ------------------------------------------------------------------------------#FreeBirdsCrew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\hp\\anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "#Used in Tensorflow Model\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import random\n",
    "\n",
    "#Usde to for Contextualisation and Other NLP Tasks.\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "#Other\n",
    "import json\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the Intents.....\n"
     ]
    }
   ],
   "source": [
    "print(\"Processing the Intents.....\")\n",
    "with open('intents.json') as json_data:\n",
    "    intents = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looping through the Intents to Convert them to words, classes, documents and ignore_words.......\n"
     ]
    }
   ],
   "source": [
    "words = []\n",
    "classes = []\n",
    "documents = []\n",
    "ignore_words = ['?']\n",
    "print(\"Looping through the Intents to Convert them to words, classes, documents and ignore_words.......\")\n",
    "for intent in intents['intents']:\n",
    "    for pattern in intent['patterns']:\n",
    "        # tokenize each word in the sentence\n",
    "        w = nltk.word_tokenize(pattern)\n",
    "        # add to our words list\n",
    "        words.extend(w)\n",
    "        # add to documents in our corpus\n",
    "        documents.append((w, intent['tag']))\n",
    "        # add to our classes list\n",
    "        if intent['tag'] not in classes:\n",
    "            classes.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemming, Lowering and Removing Duplicates.......\n",
      "315 documents\n",
      "75 classes ['Cotton_irrigation', 'Cotton_rainfall', 'Cotton_soil', 'Cotton_sowing_time', 'Jowar_irrigation', 'Pulses_soil', 'Sugarcane_soil', 'Sugarcane_sowing_time', 'cotton_fertiliser', 'cotton_maturity_time', 'cotton_pesticide', 'cotton_seedrate', 'cotton_yield', 'goodbye', 'greeting', 'jowar_fertiliser', 'jowar_maturity_time', 'jowar_pesticide', 'jowar_rainfall', 'jowar_seedrate', 'jowar_soil', 'jowar_sowing_time', 'jowar_yield', 'maize_fertiliser', 'maize_irrigation', 'maize_maturity_time', 'maize_pesticide', 'maize_rainfall', 'maize_seedrate', 'maize_soil', 'maize_sowing_time', 'maize_yield', 'pulses_fertiliser', 'pulses_irrigation', 'pulses_maturity_time', 'pulses_pesticide', 'pulses_rainfall', 'pulses_seedrate', 'pulses_sowing_time', 'pulses_yield', 'ragi_fertiliser', 'ragi_irrigation', 'ragi_maturity_time', 'ragi_pesticide', 'ragi_rainfall', 'ragi_seedrate', 'ragi_soil', 'ragi_sowing_time', 'ragi_yield', 'rice_fertiliser', 'rice_irrigation', 'rice_maturity_time', 'rice_pesticide', 'rice_rainfall', 'rice_seedrate', 'rice_soil', 'rice_sowing_time', 'rice_yield', 'sugarcane_fertiliser', 'sugarcane_irrigation', 'sugarcane_maturity_time', 'sugarcane_pesticide', 'sugarcane_rainfall', 'sugarcane_seedrate', 'sugarcane_yield', 'thanks', 'wheat_fertiliser', 'wheat_irrigation', 'wheat_maturity_time', 'wheat_pesticide', 'wheat_rainfall', 'wheat_seedrate', 'wheat_soil', 'wheat_sowing_time', 'wheat_yield']\n",
      "50 unique stemmed words [\"'s\", 'amount', 'anyon', 'ar', 'av', 'avg', 'bye', 'cotton', 'day', 'fertil', 'fertl', 'for', 'good', 'goodby', 'hello', 'help', 'hi', 'how', 'irrig', 'is', 'jow', 'lat', 'maiz', 'mat', 'of', 'period', 'pesticid', 'pot', 'puls', 'rag', 'rain', 'rainfal', 'rat', 'requir', 'ric', 'see', 'soil', 'sow', 'sugarc', 'suit', 'thank', 'that', 'the', 'ther', 'tim', 'what', 'whe', 'yeild', 'yield', 'you']\n"
     ]
    }
   ],
   "source": [
    "print(\"Stemming, Lowering and Removing Duplicates.......\")\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# remove duplicates\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print (len(documents), \"documents\")\n",
    "print (len(classes), \"classes\", classes)\n",
    "print (len(words), \"unique stemmed words\", words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the Data for our Model.....\n",
      "Creating an List (Empty) for Output.....\n",
      "Creating Traning Set, Bag of Words for our Model....\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating the Data for our Model.....\")\n",
    "training = []\n",
    "output = []\n",
    "print(\"Creating an List (Empty) for Output.....\")\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "print(\"Creating Traning Set, Bag of Words for our Model....\")\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    # stem each word\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "\n",
    "    # output is a '0' for each tag and '1' for current tag\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shuffling Randomly and Converting into Numpy Array for Faster Processing......\n",
      "Creating Train and Test Lists.....\n",
      "Building Neural Network for Out Chatbot to be Contextual....\n",
      "Resetting graph data....\n"
     ]
    }
   ],
   "source": [
    "print(\"Shuffling Randomly and Converting into Numpy Array for Faster Processing......\")\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "print(\"Creating Train and Test Lists.....\")\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])\n",
    "print(\"Building Neural Network for Out Chatbot to be Contextual....\")\n",
    "print(\"Resetting graph data....\")\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "#net = tflearn.fully_connected(net, 8)\n",
    "#net = tflearn.fully_connected(net, 8)\n",
    "#net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
    "#net = tflearn.regression(net)\n",
    "#print(\"Training....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simpletransformers"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: tensorflow 2.5.0 has requirement typing-extensions~=3.7.4, but you'll have typing-extensions 4.0.0 which is incompatible.\n",
      "ERROR: huggingface-hub 0.1.2 has requirement packaging>=20.9, but you'll have packaging 20.4 which is incompatible.\n",
      "ERROR: datasets 1.15.1 has requirement tqdm>=4.62.1, but you'll have tqdm 4.47.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading simpletransformers-0.63.3-py3-none-any.whl (247 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from simpletransformers) (0.23.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from simpletransformers) (2.24.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from simpletransformers) (1.19.5)\n",
      "Collecting wandb>=0.10.32\n",
      "  Downloading wandb-0.12.7-py2.py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (from simpletransformers) (1.0.5)\n",
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.10.3-cp38-cp38-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from simpletransformers) (1.5.0)\n",
      "Collecting streamlit\n",
      "  Downloading streamlit-1.2.0-py2.py3-none-any.whl (9.1 MB)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "Requirement already satisfied: tensorboard in c:\\users\\hp\\anaconda3\\lib\\site-packages (from simpletransformers) (2.5.0)\n",
      "Requirement already satisfied: regex in c:\\users\\hp\\anaconda3\\lib\\site-packages (from simpletransformers) (2020.6.8)\n",
      "Collecting transformers>=4.6.0\n",
      "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-win_amd64.whl (1.1 MB)\n",
      "Requirement already satisfied: tqdm>=4.47.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from simpletransformers) (4.47.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-1.15.1-py3-none-any.whl (290 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->simpletransformers) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->simpletransformers) (2.1.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->simpletransformers) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->simpletransformers) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->simpletransformers) (1.25.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->simpletransformers) (2020.6.20)\n",
      "Requirement already satisfied: six>=1.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (1.15.0)\n",
      "Collecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
      "Collecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (3.17.3)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (5.3.1)\n",
      "Collecting yaspin>=1.0.0\n",
      "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pathtools in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (0.1.2)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (7.1.2)\n",
      "Collecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (5.7.0)\n",
      "Collecting sentry-sdk>=1.0.0\n",
      "  Downloading sentry_sdk-1.5.0-py2.py3-none-any.whl (140 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (2.8.1)\n",
      "Collecting configparser>=3.8.1\n",
      "  Downloading configparser-5.1.0-py3-none-any.whl (19 kB)\n",
      "Collecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas->simpletransformers) (2020.1)\n",
      "Collecting pympler>=0.9\n",
      "  Downloading Pympler-0.9.tar.gz (178 kB)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.7.1-py2.py3-none-any.whl (4.3 MB)\n",
      "Collecting validators\n",
      "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
      "Collecting blinker\n",
      "  Downloading blinker-1.4.tar.gz (111 kB)\n",
      "Requirement already satisfied: toml in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (0.10.1)\n",
      "Requirement already satisfied: watchdog; platform_system != \"Darwin\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (0.10.3)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (6.0.4)\n",
      "Collecting base58\n",
      "  Downloading base58-2.1.1-py3-none-any.whl (5.6 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (7.2.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (20.4)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.1.0-py3-none-any.whl (727 kB)\n",
      "Requirement already satisfied: tzlocal in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (4.1)\n",
      "Collecting astor\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Requirement already satisfied: attrs in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (19.3.0)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-6.0.1-cp38-cp38-win_amd64.whl (15.5 MB)\n",
      "Requirement already satisfied: cachetools>=4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from streamlit->simpletransformers) (4.2.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (0.4.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (49.2.0.post20200714)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (0.6.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (0.13.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (1.34.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (0.36.2)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (1.34.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tensorboard->simpletransformers) (1.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers>=4.6.0->simpletransformers) (3.0.12)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
      "Collecting dill\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting multiprocess\n",
      "  Downloading multiprocess-0.70.12.2-py38-none-any.whl (128 kB)\n",
      "Collecting fsspec[http]>=2021.05.0\n",
      "  Downloading fsspec-2021.11.0-py3-none-any.whl (132 kB)\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp38-cp38-win_amd64.whl (555 kB)\n",
      "Collecting xxhash\n",
      "  Downloading xxhash-2.0.2-cp38-cp38-win_amd64.whl (35 kB)\n",
      "Collecting typing-extensions>=3.7.4.3; python_version < \"3.10\"\n",
      "  Using cached typing_extensions-4.0.0-py3-none-any.whl (22 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
      "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from yaspin>=1.0.0->wandb>=0.10.32->simpletransformers) (1.1.0)\n",
      "Requirement already satisfied: ipykernel>=5.1.2; python_version >= \"3.4\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (5.3.2)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (7.5.1)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (4.3.3)\n",
      "Requirement already satisfied: jinja2>=2.10.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (2.11.2)\n",
      "Requirement already satisfied: decorator>=3.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from validators->streamlit->simpletransformers) (4.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from packaging->streamlit->simpletransformers) (2.4.7)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\hp\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.3)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\hp\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit->simpletransformers) (3.2.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\hp\\anaconda3\\lib\\site-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.10.0)\n",
      "Requirement already satisfied: tzdata; platform_system == \"Windows\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tzlocal->streamlit->simpletransformers) (2021.5)\n",
      "Requirement already satisfied: pytz-deprecation-shim in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tzlocal->streamlit->simpletransformers) (0.1.0.post0)\n",
      "Requirement already satisfied: backports.zoneinfo; python_version < \"3.9\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tzlocal->streamlit->simpletransformers) (0.2.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (1.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->simpletransformers) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard->simpletransformers) (0.2.8)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.2.0-cp38-cp38-win_amd64.whl (83 kB)\n",
      "Collecting charset-normalizer<3.0,>=2.0\n",
      "  Using cached charset_normalizer-2.0.8-py3-none-any.whl (39 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.7.2-cp38-cp38-win_amd64.whl (122 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-5.2.0-cp38-cp38-win_amd64.whl (45 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting smmap<6,>=3.0.1\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (6.1.6)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (7.16.1)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.5.1)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.0.7)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\hp\\anaconda3\\lib\\site-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jinja2>=2.10.1->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.1.1)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jsonschema->altair>=3.2.0->streamlit->simpletransformers) (0.16.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->simpletransformers) (3.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard->simpletransformers) (0.4.8)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.6.3)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (19.0.1)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.0.5)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.5)\n",
      "Requirement already satisfied: colorama; sys_platform == \"win32\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.4.3)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.17.1)\n",
      "Requirement already satisfied: backcall in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.6.1)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (6.0.3)\n",
      "Requirement already satisfied: pywin32>=1.0; sys_platform == \"win32\" in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (227)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hp\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.5)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\hp\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.3)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\hp\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.5.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\hp\\anaconda3\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.6.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.4)\n",
      "Requirement already satisfied: testpath in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.4.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.4.2)\n",
      "Requirement already satisfied: bleach in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.1.5)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\hp\\anaconda3\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.6.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\hp\\anaconda3\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.5.1)\n",
      "Building wheels for collected packages: seqeval, promise, subprocess32, pympler, blinker\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16170 sha256=f507aa274ecdd42f485099b9bd1dc2894ca4ba83417216fe217094056b9ceb3a\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\ad\\5c\\ba\\05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=bdc937b642337fbc22dd939576bc3fb841a2b270fe67323ec8897baaea7a11c6\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\54\\aa\\01\\724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "  Building wheel for subprocess32 (setup.py): started\n",
      "  Building wheel for subprocess32 (setup.py): finished with status 'done'\n",
      "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6488 sha256=301b7a0c9d2c754d9512b609b17bbea5c03eae833d92d5529e29ecb212843dca\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\9f\\69\\d1\\50b39b308a87998eaf5c1d9095e5a5bd2ad98501e2b7936d36\n",
      "  Building wheel for pympler (setup.py): started\n",
      "  Building wheel for pympler (setup.py): finished with status 'done'\n",
      "  Created wheel for pympler: filename=Pympler-0.9-py3-none-any.whl size=164803 sha256=068a4e62986c45791f3fccac9eb23d8b22c88e78d7d616d44d13ea5349f018d4\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\24\\6f\\0b\\da9f81234859a8741aaea3afcc6ae2daf0efb67e7ff2d3686c\n",
      "  Building wheel for blinker (setup.py): started\n",
      "  Building wheel for blinker (setup.py): finished with status 'done'\n",
      "  Created wheel for blinker: filename=blinker-1.4-py3-none-any.whl size=13451 sha256=148f88727cf97d9f4c7efb93e558bc01d3bf2ac79ac4753ad6bc9883b728fe94\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\b7\\a5\\68\\fe632054a5eadd531c7a49d740c50eb6adfbeca822b4eab8d4\n",
      "Successfully built seqeval promise subprocess32 pympler blinker\n",
      "Installing collected packages: typing-extensions, smmap, gitdb, GitPython, promise, yaspin, docker-pycreds, shortuuid, sentry-sdk, configparser, subprocess32, wandb, tokenizers, pympler, pydeck, validators, blinker, base58, altair, astor, pyarrow, streamlit, seqeval, sacremoses, huggingface-hub, transformers, sentencepiece, dill, multiprocess, frozenlist, charset-normalizer, multidict, yarl, async-timeout, aiosignal, aiohttp, fsspec, xxhash, datasets, simpletransformers\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.7.4.2\n",
      "    Uninstalling typing-extensions-3.7.4.2:\n",
      "      Successfully uninstalled typing-extensions-3.7.4.2\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 0.7.4\n",
      "    Uninstalling fsspec-0.7.4:\n",
      "      Successfully uninstalled fsspec-0.7.4\n",
      "Successfully installed GitPython-3.1.24 aiohttp-3.8.1 aiosignal-1.2.0 altair-4.1.0 astor-0.8.1 async-timeout-4.0.1 base58-2.1.1 blinker-1.4 charset-normalizer-2.0.8 configparser-5.1.0 datasets-1.15.1 dill-0.3.4 docker-pycreds-0.4.0 frozenlist-1.2.0 fsspec-2021.11.0 gitdb-4.0.9 huggingface-hub-0.1.2 multidict-5.2.0 multiprocess-0.70.12.2 promise-2.3 pyarrow-6.0.1 pydeck-0.7.1 pympler-0.9 sacremoses-0.0.46 sentencepiece-0.1.96 sentry-sdk-1.5.0 seqeval-1.2.2 shortuuid-1.0.8 simpletransformers-0.63.3 smmap-5.0.0 streamlit-1.2.0 subprocess32-3.5.4 tokenizers-0.10.3 transformers-4.12.5 typing-extensions-4.0.0 validators-0.18.2 wandb-0.12.7 xxhash-2.0.2 yarl-1.7.2 yaspin-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install simpletransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(r\"intents.json\", \"r\") as read_file:\n",
    "    train = json.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.10.0-cp38-cp38-win_amd64.whl (226.6 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\hp\\anaconda3\\lib\\site-packages (from torch) (4.0.0)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.10.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: typing-extensions in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install typing-extensions --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "try:\n",
    "    from typing import Literal\n",
    "except ImportError:\n",
    "    from typing_extensions import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: typing_extensions in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install typing_extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement TypeAlias (from versions: none)\n",
      "ERROR: No matching distribution found for TypeAlias\n"
     ]
    }
   ],
   "source": [
    "!pip install TypeAlias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'TypeAlias' from 'typing_extensions' (C:\\Users\\hp\\anaconda3\\lib\\site-packages\\typing_extensions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-830abeca40fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquestion_answering\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQuestionAnsweringModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mQuestionAnsweringArgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\simpletransformers\\question_answering\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_args\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mQuestionAnsweringArgs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m from simpletransformers.question_answering.question_answering_model import (\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mQuestionAnsweringModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\simpletransformers\\question_answering\\question_answering_model.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDistributedSampler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrange\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m from transformers.optimization import (\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[0mget_constant_schedule\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mget_constant_schedule_with_warmup\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# Check the dependencies satisfy the minimal versions required.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdependency_versions_check\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m from .file_utils import (\n\u001b[0;32m     45\u001b[0m     \u001b[0m_LazyModule\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\dependency_versions_check.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpkg\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"tokenizers\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[1;31m# must be loaded here, or else tqdm check may fail\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m             \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfile_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_tokenizers_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\file_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfilelock\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFileLock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHfApi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRepository\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimportlib_metadata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\huggingface_hub\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mwhoami\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m )\n\u001b[1;32m---> 55\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhub_mixin\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModelHubMixin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPyTorchModelHubMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0minference_api\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mInferenceApi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m from .keras_mixin import (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\huggingface_hub\\hub_mixin.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfile_download\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhf_hub_download\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhf_api\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHfApi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrepository\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRepository\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\huggingface_hub\\repository.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mREPO_TYPES_URL_PREFIXES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mREPOCARD_NAME\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepocard\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmetadata_load\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata_save\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mhf_api\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mENDPOINT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHfApi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mHfFolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepo_type_and_id_from_hf_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\huggingface_hub\\repocard.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0myaml\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m from huggingface_hub.repocard_types import (\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mModelIndex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mSingleMetric\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\huggingface_hub\\repocard_types.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping_extensions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTypeAlias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'TypeAlias' from 'typing_extensions' (C:\\Users\\hp\\anaconda3\\lib\\site-packages\\typing_extensions.py)"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "from simpletransformers.question_answering import QuestionAnsweringModel, QuestionAnsweringArgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type=\"bert\"\n",
    "model_name= \"bert-base-cased\"\n",
    "if model_type == \"bert\":\n",
    "    model_name = \"bert-base-cased\"\n",
    "\n",
    "elif model_type == \"roberta\":\n",
    "    model_name = \"roberta-base\"\n",
    "\n",
    "elif model_type == \"distilbert\":\n",
    "    model_name = \"distilbert-base-cased\"\n",
    "\n",
    "elif model_type == \"distilroberta\":\n",
    "    model_type = \"roberta\"\n",
    "    model_name = \"distilroberta-base\"\n",
    "\n",
    "elif model_type == \"electra-base\":\n",
    "    model_type = \"electra\"\n",
    "    model_name = \"google/electra-base-discriminator\"\n",
    "\n",
    "elif model_type == \"electra-small\":\n",
    "    model_type = \"electra\"\n",
    "    model_name = \"google/electra-small-discriminator\"\n",
    "elif model_type == \"xlnet\":\n",
    "    model_name = \"xlnet-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = QuestionAnsweringArgs()\n",
    "model_args.train_batch_size = 16\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.n_best_size=3\n",
    "model_args.num_train_epochs=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = {\n",
    "    \"reprocess_input_data\": True,\n",
    "    \"overwrite_output_dir\": True,\n",
    "    \"use_cached_eval_features\": True,\n",
    "    \"output_dir\": f\"outputs/{model_type}\",\n",
    "    \"best_model_dir\": f\"outputs/{model_type}/best_model\",\n",
    "    \"evaluate_during_training\": True,\n",
    "    \"max_seq_length\": 128,\n",
    "    \"num_train_epochs\": 5,\n",
    "    \"evaluate_during_training_steps\": 1000,\n",
    "    \"wandb_project\": \"Question Answer Application\",\n",
    "    \"wandb_kwargs\": {\"name\": model_name},\n",
    "    \"save_model_every_epoch\": False,\n",
    "    \"save_eval_checkpoints\": False,\n",
    "    \"n_best_size\":3\n",
    "    # \"use_early_stopping\": True,\n",
    "    # \"early_stopping_metric\": \"mcc\",\n",
    "    # \"n_gpu\": 2,\n",
    "    # \"manual_seed\": 4,\n",
    "    # \"use_multiprocessing\": False,\n",
    "    \"train_batch_size\": 128,\n",
    "    \"eval_batch_size\": 64,\n",
    "    # \"config\": {\n",
    "    #     \"output_hidden_states\": True\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = QuestionAnsweringModel(\n",
    "    model_type,model_name, args=train_args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#important\n",
    "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "net = tflearn.fully_connected(net, 128)\n",
    "net = tflearn.fully_connected(net, 128)\n",
    "net = tflearn.fully_connected(net, len(train_y[0]), activation='relu')\n",
    "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "print(\"Training....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#92 percent\n",
    "#net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "#net = tflearn.fully_connected(net, 128)\n",
    "#net = tflearn.fully_connected(net, 128)\n",
    "#net = tflearn.fully_connected(net, 64)\n",
    "#net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
    "#net = tflearn.regression(net)\n",
    "#print(\"Training....\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training the Model.......\")\n",
    "model.fit(train_x, train_y, n_epoch=1000, batch_size=8, show_metric=True)\n",
    "print(\"Saving the Model.......\")\n",
    "model.save('model.tflearn')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pickle is also Saved..........\")\n",
    "pickle.dump( {'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y}, open( \"training_data\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading Pickle.....\")\n",
    "data = pickle.load( open( \"training_data\", \"rb\" ) )\n",
    "words = data['words']\n",
    "classes = data['classes']\n",
    "train_x = data['train_x']\n",
    "train_y = data['train_y']\n",
    "\n",
    "\n",
    "with open('intents.json') as json_data:\n",
    "    intents = json.load(json_data)\n",
    "    \n",
    "print(\"Loading the Model......\")\n",
    "# load our saved model\n",
    "model.load('./model.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # It Tokenize or Break it into the constituents parts of Sentense.\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # Stemming means to find the root of the word.\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    return sentence_words\n",
    "\n",
    "# Return the Array of Bag of Words: True or False and 0 or 1 for each word of bag that exists in the Sentence\n",
    "def bow(sentence, words, show_details=False):\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    bag = [0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s:\n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "    return(np.array(bag))\n",
    "\n",
    "ERROR_THRESHOLD = 0.25\n",
    "print(\"ERROR_THRESHOLD = 0.25\")\n",
    "\n",
    "def classify(sentence):\n",
    "    # Prediction or To Get the Posibility or Probability from the Model\n",
    "    results = model.predict([bow(sentence, words)])[0]\n",
    "    # Exclude those results which are Below Threshold\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # Sorting is Done because heigher Confidence Answer comes first.\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], r[1])) #Tuppl -> Intent and Probability\n",
    "    return return_list\n",
    "\n",
    "def response(sentence, userID='123', show_details=False):\n",
    "    results = classify(sentence)\n",
    "    # That Means if Classification is Done then Find the Matching Tag.\n",
    "    if results:\n",
    "        # Long Loop to get the Result.\n",
    "        while results:\n",
    "            for i in intents['intents']:\n",
    "                # Tag Finding\n",
    "                if i['tag'] == results[0][0]:\n",
    "                    # Random Response from High Order Probabilities\n",
    "                    return print(random.choice(i['responses']))\n",
    "\n",
    "            results.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    input_data = input(\"You- \")\n",
    "    answer = response(input_data)\n",
    "    answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
